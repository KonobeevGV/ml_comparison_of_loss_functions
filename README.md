# ml_comparison_of_loss_functions
Этот репозиторий содержит код и анализ данных, где применяются три метода машинного обучения для решения задачи регрессии: линейная регрессия, Lasso и Ridge. Основная цель проекта — изучить, как разные методы регрессии справляются с задачей предсказания, и сравнить их производительность на основе метрик качества.

Основные шаги:
Предобработка данных: Данные очищаются и подготавливаются для обучения моделей.

Применение методов регрессии:

Линейная регрессия: Базовый метод, который минимизирует сумму квадратов ошибок.

Lasso (L1-регуляризация): Метод, который добавляет штраф за абсолютные значения коэффициентов, что помогает отбирать признаки.

Ridge (L2-регуляризация): Метод, который добавляет штраф за квадраты коэффициентов, что помогает бороться с мультиколлинеарностью.

Подбор гиперпараметров: Для Lasso и Ridge с помощью кросс-валидации подбираются оптимальные значения гиперпараметров (например, коэффициент регуляризации alpha).

Обучение моделей: Модели обучаются на обучающей выборке с лучшими гиперпараметрами.

Оценка качества: Качество моделей оценивается на тестовой выборке с использованием метрик:

RMSE (Root Mean Squared Error): Среднеквадратичная ошибка, которая показывает, насколько сильно предсказания отклоняются от истинных значений.

MAE (Mean Absolute Error): Средняя абсолютная ошибка, которая менее чувствительна к выбросам.

R^2 (Коэффициент детерминации): Показывает, насколько хорошо модель объясняет дисперсию целевой переменной.

Результаты:
Сравнение качества моделей по метрикам RMSE, MAE и R^2

Анализ влияния регуляризации на производительность моделей.

Выводы о том, какой метод лучше справляется с задачей на данном наборе данных.
